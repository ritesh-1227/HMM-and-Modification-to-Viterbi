{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import nltk, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')]]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "nltk_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Set Length : 3718\nTraining Set Length : 196\n==================================================================================================================================================================================\nTraining Data sample :\n\n[[('Any', 'DET'), ('money', 'NOUN'), ('in', 'ADP'), ('excess', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('40', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('collected', 'VERB'), ('*', 'X'), ('from', 'ADP'), ('the', 'DET'), ('fees', 'NOUN'), ('in', 'ADP'), ('fiscal', 'ADJ'), ('1990', 'NUM'), ('would', 'VERB'), ('go', 'VERB'), ('to', 'PRT'), ('the', 'DET'), ('Treasury', 'NOUN'), ('at', 'ADP'), ('large', 'ADJ'), ('.', '.')], [('Stock-index', 'NOUN'), ('futures', 'NOUN'), ('--', '.'), ('Contracts', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('buy', 'VERB'), ('or', 'CONJ'), ('sell', 'VERB'), ('the', 'DET'), ('cash', 'NOUN'), ('value', 'NOUN'), ('of', 'ADP'), ('a', 'DET'), ('stock', 'NOUN'), ('index', 'NOUN'), ('by', 'ADP'), ('a', 'DET'), ('certain', 'ADJ'), ('date', 'NOUN'), ('.', '.')], [('All', 'DET'), ('came', 'VERB'), ('from', 'ADP'), ('Cray', 'NOUN'), ('Research', 'NOUN'), ('.', '.')], [('Yasser', 'NOUN'), ('Arafat', 'NOUN'), ('has', 'VERB'), ('written', 'VERB'), ('to', 'PRT'), ('the', 'DET'), ('chairman', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('International', 'NOUN'), ('Olympic', 'NOUN'), ('Committee', 'NOUN'), ('*-2', 'X'), ('asking', 'VERB'), ('him', 'PRON'), ('*-3', 'X'), ('to', 'PRT'), ('back', 'VERB'), ('a', 'DET'), ('Palestinian', 'ADJ'), ('bid', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('join', 'VERB'), ('the', 'DET'), ('committee', 'NOUN'), (',', '.'), ('the', 'DET'), ('Palestine', 'NOUN'), ('Liberation', 'NOUN'), ('Organization', 'NOUN'), ('news', 'NOUN'), ('agency', 'NOUN'), ('WAFA', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('INTER-TEL', 'NOUN'), ('Inc', 'NOUN'), ('.', '.'), ('-LRB-', '.'), ('Chandler', 'NOUN'), (',', '.'), ('Ariz.', 'NOUN'), ('-RRB-', '.'), ('--', '.')], [('*-1', 'X'), ('To', 'PRT'), ('further', 'ADV'), ('load', 'VERB'), ('the', 'DET'), ('stakes', 'NOUN'), (',', '.'), ('Mr.', 'NOUN'), ('Lane', 'NOUN'), ('dreamed', 'VERB'), ('up', 'PRT'), ('a', 'DET'), ('highly', 'ADV'), ('improbable', 'ADJ'), ('romance', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('Artist', 'NOUN'), (',', '.'), ('with', 'ADP'), ('a', 'DET'), ('young', 'ADJ'), ('woman', 'NOUN'), ('who', 'PRON'), ('*T*-68', 'X'), ('owns', 'VERB'), ('her', 'PRON'), ('own', 'ADJ'), ('children', 'NOUN'), (\"'s\", 'PRT'), ('shop', 'NOUN'), ('and', 'CONJ'), ('who', 'PRON'), ('*T*-69', 'X'), ('lives', 'VERB'), ('in', 'ADP'), ('an', 'DET'), ('expensive', 'ADJ'), ('high-rise', 'ADJ'), ('apartment', 'NOUN'), ('building', 'NOUN'), ('.', '.')], [('The', 'DET'), ('parishioners', 'NOUN'), ('of', 'ADP'), ('St.', 'NOUN'), ('Michael', 'NOUN'), ('and', 'CONJ'), ('All', 'DET'), ('Angels', 'NOUN'), ('stop', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('chat', 'VERB'), ('at', 'ADP'), ('the', 'DET'), ('church', 'NOUN'), ('door', 'NOUN'), (',', '.'), ('as', 'ADP'), ('members', 'NOUN'), ('here', 'ADV'), ('always', 'ADV'), ('have', 'VERB'), ('*?*', 'X'), ('.', '.')], [('The', 'DET'), ('Spiegel', 'NOUN'), ('family', 'NOUN'), ('has', 'VERB'), ('25', 'NUM'), ('%', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('common', 'ADJ'), ('and', 'CONJ'), ('75', 'NUM'), ('%', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('votes', 'NOUN'), ('.', '.')], [('Speculation', 'NOUN'), ('had', 'VERB'), ('it', 'PRON'), ('that', 'ADP'), ('the', 'DET'), ('company', 'NOUN'), ('was', 'VERB'), ('asking', 'VERB'), ('$', '.'), ('100', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('for', 'ADP'), ('an', 'DET'), ('operation', 'NOUN'), ('said', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('losing', 'VERB'), ('about', 'ADP'), ('$', '.'), ('20', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('a', 'DET'), ('year', 'NOUN'), (',', '.'), ('but', 'CONJ'), ('others', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('Hearst', 'NOUN'), ('might', 'VERB'), ('have', 'VERB'), ('virtually', 'ADV'), ('given', 'VERB'), ('the', 'DET'), ('paper', 'NOUN'), ('away', 'ADV'), ('.', '.')], [('A', 'DET'), ('former', 'ADJ'), ('member', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('prosecution', 'NOUN'), ('team', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('Iran\\\\/Contra', 'NOUN'), ('affair', 'NOUN'), ('joined', 'VERB'), ('the', 'DET'), ('Chicago', 'NOUN'), ('firm', 'NOUN'), ('of', 'ADP'), ('Mayer', 'NOUN'), (',', '.'), ('Brown', 'NOUN'), ('&', 'CONJ'), ('Platt', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(42)\n",
    "train_set, test_set = train_test_split(nltk_data, test_size=0.05)\n",
    "\n",
    "print(\"Training Set Length :\", len(train_set))\n",
    "print(\"Training Set Length :\", len(test_set))\n",
    "print(\"==\" * 89)\n",
    "print(\"Training Data sample :\\n\")\n",
    "print(train_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Num of tuples : 95558\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Any', 'DET'),\n",
       " ('money', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('excess', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('40', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('collected', 'VERB')]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Get list of tagged tuples\n",
    "\n",
    "train_tagged_tup = [tup for sent in train_set for tup in sent]\n",
    "print(f\" Num of tuples : {len(train_tagged_tup)}\")\n",
    "train_tagged_tup[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'money',\n",
       " 'in',\n",
       " 'excess',\n",
       " 'of',\n",
       " '$',\n",
       " '40',\n",
       " 'million',\n",
       " '*U*',\n",
       " 'collected']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Get a list of tagged words\n",
    "\n",
    "train_tagged_words = [pair[0] for pair in train_tagged_tup]\n",
    "train_tagged_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['DET', 'NOUN', 'ADP', 'NOUN', 'ADP', '.', 'NUM', 'NUM', 'X', 'VERB']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Get a list of tags \n",
    "\n",
    "train_tagged_tags = [pair[1] for pair in train_tagged_tup]\n",
    "train_tagged_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocabulary_length : 12077 \nTagset_length : 12\n\n\nAvailable tags : {'.', 'VERB', 'PRON', 'NOUN', 'ADV', 'DET', 'ADP', 'ADJ', 'X', 'NUM', 'PRT', 'CONJ'}\n"
     ]
    }
   ],
   "source": [
    "## Building the vocabulary and the POS tag sets (haivng unique occurences)\n",
    "\n",
    "train_vocab = set(train_tagged_words)\n",
    "train_tags = set(train_tagged_tags)\n",
    "\n",
    "print(f\"Vocabulary_length : {len(train_vocab)} \\nTagset_length : {len(train_tags)}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Available tags : {train_tags}\")"
   ]
  },
  {
   "source": [
    "### Emission and Transition probabilities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tags = len(train_tags)\n",
    "len_vocab = len(train_vocab)\n",
    "\n",
    "word_given_tag = np.zeros((len_tags, len_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computing emission probability (Word given tag = P(word | tag))\n",
    "\n",
    "def word_given_tag(word, train_bag = train_tagged_tup):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing Transition Probability (tag2(t2) given tag1 (t1) = P(tag2 | tag1))\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_tup):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[9.27253217e-02, 8.87833685e-02, 6.60275966e-02, 2.22809538e-01,\n",
       "        5.17828353e-02, 1.72997668e-01, 9.13814753e-02, 4.38989438e-02,\n",
       "        2.65185442e-02, 8.17057863e-02, 2.32933159e-03, 5.89500107e-02],\n",
       "       [3.53535339e-02, 1.69075370e-01, 3.62082347e-02, 1.10644914e-01,\n",
       "        8.18958804e-02, 1.34343430e-01, 9.14529935e-02, 6.41025677e-02,\n",
       "        2.17094019e-01, 2.30769236e-02, 3.13908309e-02, 5.36130555e-03],\n",
       "       [4.14921977e-02, 4.85725164e-01, 7.61324726e-03, 2.08983630e-01,\n",
       "        3.27369608e-02, 9.89722088e-03, 2.24590786e-02, 7.42291585e-02,\n",
       "        9.13589671e-02, 7.61324726e-03, 1.25618577e-02, 5.32927271e-03],\n",
       "       [2.40799502e-01, 1.46296099e-01, 4.55921516e-03, 2.65091002e-01,\n",
       "        1.70697011e-02, 1.33129079e-02, 1.76058650e-01, 1.21822227e-02,\n",
       "        2.87777651e-02, 9.51964129e-03, 4.39508334e-02, 4.23824638e-02],\n",
       "       [1.36287898e-01, 3.44885051e-01, 1.56614464e-02, 3.06564476e-02,\n",
       "        8.09730068e-02, 6.79773390e-02, 1.17627457e-01, 1.29956678e-01,\n",
       "        2.26591136e-02, 3.16561162e-02, 1.46617796e-02, 6.99766725e-03],\n",
       "       [1.74291935e-02, 3.95787954e-02, 3.51004605e-03, 6.40764952e-01,\n",
       "        1.24667147e-02, 5.08351484e-03, 9.19874106e-03, 2.03703701e-01,\n",
       "        4.57516350e-02, 2.17864923e-02, 2.42072143e-04, 4.84144286e-04],\n",
       "       [4.05231565e-02, 8.57632887e-03, 7.07547143e-02, 3.22255582e-01,\n",
       "        1.32933101e-02, 3.23327601e-01, 1.71526577e-02, 1.05703257e-01,\n",
       "        3.45197245e-02, 6.16423674e-02, 1.39365357e-03, 8.57632956e-04],\n",
       "       [6.52858317e-02, 1.20961061e-02, 4.97100234e-04, 7.00414240e-01,\n",
       "        4.80530225e-03, 4.97100269e-03, 7.70505369e-02, 6.57829344e-02,\n",
       "        2.17067115e-02, 2.02154107e-02, 1.01077054e-02, 1.70671083e-02],\n",
       "       [1.64672092e-01, 2.03127488e-01, 5.60076609e-02, 6.14329018e-02,\n",
       "        2.52114255e-02, 5.55289611e-02, 1.42971113e-01, 1.73926912e-02,\n",
       "        7.48364478e-02, 2.87218764e-03, 1.85415670e-01, 1.05313547e-02],\n",
       "       [1.16251484e-01, 1.74970347e-02, 1.77935942e-03, 3.53202850e-01,\n",
       "        2.96559907e-03, 2.96559907e-03, 3.38078290e-02, 3.20284702e-02,\n",
       "        2.13819697e-01, 1.85053378e-01, 2.75800712e-02, 1.30486358e-02],\n",
       "       [4.37908508e-02, 4.00980383e-01, 1.76470596e-02, 2.46078432e-01,\n",
       "        9.80392192e-03, 9.93464068e-02, 2.12418307e-02, 8.52941200e-02,\n",
       "        1.37254903e-02, 5.78431375e-02, 1.96078443e-03, 2.28758180e-03],\n",
       "       [3.61613370e-02, 1.58553541e-01, 5.98052852e-02, 3.43532681e-01,\n",
       "        5.47056086e-02, 1.18683353e-01, 5.37783951e-02, 1.19146965e-01,\n",
       "        7.88131636e-03, 4.21882235e-02, 5.09967562e-03, 4.63606848e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tag_toTag_matrix = np.zeros((len_tags, len_tags), dtype='float32')\n",
    "for i, t1 in enumerate(list(train_tags)):\n",
    "    for j, t2 in enumerate(list(train_tags)): \n",
    "        tag_toTag_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "\n",
    "tag_toTag_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}